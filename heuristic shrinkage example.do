*** CODE FOR THE PRE-ECLAMPSIA EXAMPLE IN SECTION 3 OF RILEY ET AL. (submitted)
*** ref: "Riley RD et al. A general sample size framework for developing or updating a predictive algorithm: with application to clinical prediction models"


pmsampsize, type(b) cstatistic(0.759) prevalence(0.68) p(10)
* suggests min of 456 needed (335 for overall risk)


******* START HERE & RUN ALL CODE AT ONCE FROM HERE TO END
*** this code is for implementing steps 6 to 10 of the sample size calculation (see Fig 3 in paper)  
*** the data setup phase has already taken place (using steps 1 to 5 in Fig 3 in the paper)
*** - here we simply read in these pre-generated development and evaluation synthetic datasets 

qui {
clear all

* create frame for development data
* this dev data is large synthetic data pre-generated by us, following steps 1 to 5 in the paper 
* it contains all the candidate predictors on both unstandardised and standardised scales
* and simulated outcome values based on the assumed reference model (see Fig 3 in paper)
* later we take a sample of size N from this data for the sample size investigation
capture frame create dev
frame dev: use "/YourLocation/RR_dev.dta", clear

* create frame for evaluation data
* this eval data is the large target population for evaluating model performance 
* (independent of the development dataset)
* it is synthetic data pre-generated by us, following steps 1 to 4 in the paper

capture frame create eval
frame eval: use "/YourLocation/RR_eval.dta", clear

frame change eval
set seed 66
*sample 100000, count
drop if _n>100000

rename true_p_new p

timer clear
timer on 1

* Number of simulations to run - your choice (larger = better but longer time)
local sim = 1000

* create matrix to store performance measures
matrix performance = J(`sim',7,.)

* set seed
set seed 1234

* run for X simulations
forvalues i=1/`sim' {

* list simulation number in matrix of performance measures
matrix performance[`i',1] = `i'

nois _dots `i' 0

* use development data
frame change dev

* create a frame for the sampled data
tempname touse
frame put *, into(`touse')
frame change `touse'

* sample N observations, sample size of interest - in  paper we consider various
local N = 75
* local N = 335
* local N = 456
* local N = 1000
sample `N', count

* fit logistic reg model with fixed set of predictors (heuristic shrinkage comes later)
capture logit outcome ageyrssd ga_diag1sd hist2sd hist3sd pcr1sd serurea11sd pcsd sbpsd trt_ahsd trt_mgso4sd

 * if there is no error then work out the results
 if _rc == 0 {
* calculate heuristic shrinkage (note this sometimes goes below zero and hence why the mean c stat is slightly less following uniform shrinkage than without)
matrix performance[`i',6] = (e(chi2) - e(df_m)) / e(chi2)

* lp excluding intercept
 gen lp_dev = (e(b)[1,1]*ageyrssd + e(b)[1,2]*ga_diag1sd + e(b)[1,3]*hist2sd + e(b)[1,4]*hist3sd + e(b)[1,5]*pcr1sd + e(b)[1,6]*serurea11sd + e(b)[1,7]*pcsd + e(b)[1,8]*sbpsd + e(b)[1,9]*trt_ahsd + e(b)[1,10]*trt_mgso4sd)
 
 gen heur_lp_dev = performance[`i',6]*lp_dev

 
 * add to the eval data too
 frame change eval 
 
  gen lp_eval = (e(b)[1,1]*ageyrssd + e(b)[1,2]*ga_diag1sd + e(b)[1,3]*hist2sd + e(b)[1,4]*hist3sd + e(b)[1,5]*pcr1sd + e(b)[1,6]*serurea11sd + e(b)[1,7]*pcsd + e(b)[1,8]*sbpsd + e(b)[1,9]*trt_ahsd + e(b)[1,10]*trt_mgso4sd)
  
  * create shrunken lp
	 gen lin_pred = performance[`i',6]*lp_eval
	 
  * back to development data to create predictions after heuristic shrinkage
  
   frame change `touse' 

logit outcome, offset(heur_lp_dev) 

gen p_dev = invlogit(e(b)[1,1] + heur_lp_dev)

* apply to make predictions in the eval data

frame change eval

gen prob_`i' = invlogit(e(b)[1,1] + lin_pred)

* back to devel data to assess chosen dca stategy winner

  frame change `touse' 


* the following works out the net benefit of the three strategies at a relevant threshold in the development data
dca outcome p_dev, nograph  xstart(0.5) xstop(0.6) xby(0.1) saving(test, replace)
* only want the first row of results for threshold of 0.5
use test, replace 
drop if _n > 1  
* now we identify the strategy that came out best based on the dev data dca result = 0 treat none, 1 treat all, 2 model
* all, none and p_dev are the names of the columns in the dca results 
gen strategy = 0 
replace strategy = 1 if all > none 
replace strategy  = 2 if p_dev > all 
summ strategy 
matrix performance[`i',7] = r(mean)




* open evaluation data	
frame change eval 

frame drop `touse'


* c-statistic
pmcstat lin_pred outcome
matrix performance[`i',2] = r(cstat)

* calibration slope
logistic outcome lin_pred, coef
matrix performance[`i',3] = _b[lin_pred]

*** Net benefit of the model
* set threshold
scalar z = 0.5

* NB of using the model (obtained by averaging over individuals)
gen model=(prob_`i'>z)*(p-((1-p)*z/(1-z))) 
sum model
matrix performance[`i',4] = r(mean)
drop model


* MAPE
gen abs_p = abs(prob_`i'-p)
sum abs_p
matrix performance[`i',5]  = r(sum)/_N

drop abs_p lin_pred lp_eval


}

}

*** calculate uncertainty in model predictions (95% intervals of predictions)
frame copy eval predictions
frame change predictions

keep p prob_*

* the uncertainty widths adds about 6 minutes 
* empirical CI width for prediction instability 
* (note we haven't got a CI each time for each model, rather this is the empirical 95% range akin to from the instability plot)
egen lower_ci = rowpctile(prob_*), p(2.5)
egen upper_ci = rowpctile(prob_*), p(97.5)
gen width = upper_ci - lower_ci
nois summ width
nois centile width, centile(2.5 50 97.5)



* Net benefit
gen all = p-(1-p)*z/(1-z)
sum all
local ENBall = r(mean) 

*NB of using the correct risks
gen correct = (p>z)*(p-(1-p)*z/(1-z))
sum correct
local ENBmax = r(mean)



*** summarise performance
*rename columns of the matrix 
mat colnames performance = sim_n cstat cslope NBmodel MAPE h_shrink strategy

frame create perf
frame perf: svmat performance, n(col)

frame change perf


* heuristic shrinkage 
nois summ h_shrink, 
nois centile h_shrink, centile(2.5 50 97.5)



* cslope 
nois summ cslope, 
nois centile cslope, centile(2.5 50 97.5)

gen slope_degrad = cslope - 1
nois summ slope_degrad
nois centile slope_degrad, centile(2.5 50 97.5)

* prob cslope between 0.9 and 1.10
gen yes1 = 0
replace yes1 = 1 if cslope >= 0.9 & cslope <= 1.1
nois  sum yes1
nois disp "P(0.9 < slope < 1.1)" " = " r(mean)

* prob cslope between 0.85 and 1.15
gen yes2 = 0
replace yes2 = 1 if cslope >= 0.85 & cslope <= 1.15
nois  sum yes2
nois disp "P(0.85 < slope < 1.15)" " = " r(mean)

* cstat
nois summ cstat
nois centile cstat, centile(2.5 50 97.5)
* true model cstat is 0.759 in eval data
gen cstat_degrad = cstat - 0.759
nois summ cstat_degrad
nois centile cstat_degrad, centile(2.5 50 97.5)


* mape
nois summ MAPE
nois centile MAPE, centile(2.5 50 97.5)


* NB based on a threshold of 0.5

* net benefit of the developed model
nois  sum NBmodel
nois  centile NBmodel, centile(2.5 50 97.5)
 
* degradation of developed model (true model net benefit is 0.407 )
 gen NBmodel_degrad = NBmodel - 0.407
nois  summ NBmodel_degrad
nois  centile NBmodel_degrad, centile(2.5 50 97.5)
 
 gen NBmodel_degrad_percent = (100*(NBmodel/0.407))
nois summ NBmodel_degrad_percent
nois centile NBmodel_degrad_percent, centile(2.5 50 97.5)

* model's assurance probability based on acheiving at least 90% of the true model NB
gen NBmodel_yes = 1
replace NBmodel_yes = 0 if NBmodel_degrad_percent < 90
nois summ NBmodel_yes
nois disp "P(NB_model >=90% of NB true model)" " = " r(mean)
 
* net benefit of the best strategy (taking strategy that came out best based on NB from development data)

gen NB_winner = NBmodel
replace NB_winner = 0 if strategy == 0
replace NB_winner = 0.363 if strategy == 1

nois summ NB_winner
nois centile NB_winner, centile(2.5 50 97.5)

gen NB_winner_degrad = NB_winner - 0.407
nois summ NB_winner_degrad
nois centile NB_winner_degrad, centile(2.5 50 97.5)

gen NB_winner_degrad_percent = (100*(NB_winner/0.407))
nois summ NB_winner_degrad_percent
nois centile NB_winner_degrad_percent, centile(2.5 50 97.5)

* winner's assurance probability based on acheiving at least 90% of the true model NB
gen NB_winner_yes = 1
replace NB_winner_yes = 0 if NB_winner_degrad_percent < 90
nois summ NB_winner_yes
nois disp "P(NB_winner >=90% of NB true model)" " = " r(mean)


 timer off 1
nois timer list 

}

****** END *****
